---
title: "Project"
output: html_document
---
# PRACTICAL MACHINE LEARNING COURSE PROJECT
*20th February, 2015*

## SYNOPSIS
This report attempted to predict how well participants perform personal activity using devices such as Jawbone Up, Nike FuelBand, and Fitbit in order to improve their health.

## Source of data
Data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants wre collected by asking the participants to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

Source of training data:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

Source of testing data:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

## Prepare reproducible results
```{r}
# load the packages
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
set.seed(12345) # set the seed
```

## Process the data
To reduce the noise, empty columns were removed from the 2 sets of data. The first 7 columns in each data set were also removed as they were not considered to be relevant to participants' performance.

The cleaned training data was partitioned for model building.
```{r}
# get training data
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))

# get testing data
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))

# remove empty columns and irrelevant columns from training and testing data
training.complete <- training[colnames(training[colSums(is.na(training)) == 0])[-(1:7)]]
testing.complete <- testing[colnames(testing[colSums(is.na(testing)) == 0])[-(1:7)]]

# check whether the data schema of the 2 data sets are the same
all.equal(training.complete[1:length(training.complete)-1], training.complete[1:length(testing.complete)-1])

# partition training data
i.patition.training <- createDataPartition(y=training.complete$classe, p=0.6, list=FALSE )
training.complete.training <- training.complete[i.patition.training,]
training.complete.testing <- training.complete[-i.patition.training,]
```

## Build the models
Models were built using decision tree and random forest method.
```{r}
# List any data if the variance is near to zero
Check.var <- nearZeroVar(training.complete, saveMetrics=TRUE)
Check.var[Check.var$nzv!=FALSE,]

# Model with decision tree
dtree.model <- rpart(classe ~ ., data=training.complete.training, method="class")
rpart.plot(dtree.model, main="Classification Tree", extra=102, under=TRUE, faclen=0)
#   Alternative plot for decision tree
## fancyRpartPlot(dtree.model, main="Classification Tree")

# Model with random forest
rforest.model <- randomForest(classe ~. , data=training.complete.training, method="class")
```

## Cross validation
The models were tested with the processed testing data set.
```{r}
# Test the decision tree model
dtree.prediction <- predict(dtree.model, training.complete.testing , type = "class")
dtree.cm <- confusionMatrix(dtree.prediction, training.complete.testing$classe)
dtree.cm

# Test the random forest model
rforest.prediction <- predict(rforest.model, training.complete.testing, type = "class")
rforest.cm <- confusionMatrix(rforest.prediction, training.complete.testing$classe)
rforest.cm
```

## Out of sample error
The out of sample error was expected to be smaller with the random forest method. 40% of the training data was used to estimate the error, which was expected to be 3% at maximum.
```{r ECHO=FALSE}
# highlight the results
Decision_Tree<-c(dtree.cm$overall[1],1-dtree.cm$overall[1])
Random_forest<-c(rforest.cm$overall[1],1-rforest.cm$overall[1])
results<-rbind(Decision_Tree,Random_forest, deparse.level = 1)
colnames(results)<-c("Accuracy","Sample Error")
results
```
The outcome is satisfactory.

## Choose the model
The test showed the random forest model is more accurate.
```{r}
# get the answer
answers <- predict(rforest.model, newdata=testing.complete )
```
```{r eval=FALSE}
# get the answer text files
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(answers)
```

## Conclusion
A model was built to evaluate the performance of doing a particular activity. With the measurements as listed in the data set, the performances can be preditced and classified into 5 classes. The error of the prediction model is acceptable.